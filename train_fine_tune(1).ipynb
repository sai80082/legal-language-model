{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d05e31d-b7f3-48b1-b96c-a393dc896d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current GPU: NVIDIA GeForce RTX 3080\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import torch\n",
    "# Check if a GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    # Get the current device index (default is 0 if no other device is specified)\n",
    "    current_device = torch.cuda.current_device()\n",
    "    \n",
    "    # Get the name of the GPU at this device index\n",
    "    gpu_name = torch.cuda.get_device_name(current_device)\n",
    "    print(f\"Current GPU: {gpu_name}\")\n",
    "else:\n",
    "    print(\"No GPU available.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec9bc621-fa0a-4b13-8c4b-50a91807801e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, Trainer, TrainingArguments\n",
    "from datasets import load_dataset\n",
    "import bitsandbytes \n",
    "compute_dtype = getattr(torch, \"float16\")\n",
    "\n",
    "\n",
    "\n",
    "# Load the base model and tokenizer\n",
    "model_id = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id,load_in_8bit=True, device_map=\"auto\") # Must be float32 for MacBooks!\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d0e0cd-41be-4fb1-ab7b-13eced8bbc6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e209acb-4fd9-46f6-9108-2d83d594f045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Instruction', 'Response'],\n",
       "    num_rows: 25600\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the training dataset\n",
    "dataset = load_dataset(\"vishnun0027/Indian-Law\")\n",
    "dataset = dataset[\"train\"]\n",
    "dataset = dataset.filter(lambda x: x[\"Instruction\"] is not None and x[\"Response\"] is not None)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc5d9ed7-6712-4321-b5ab-b3ec27a6b3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_token_lengths(dataset, text_column=\"text\"):\n",
    "    # Load tokenizer\n",
    "    \n",
    "    # Tokenize and get lengths\n",
    "    token_lengths = []\n",
    "    for entry in dataset:\n",
    "        # print(entry)\n",
    "        tokens = tokenizer(entry[text_column], truncation=True, padding=False)\n",
    "        token_lengths.append(len(tokens[\"input_ids\"]))\n",
    "    \n",
    "    # Plot histogram of token lengths\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(token_lengths, bins=10, color=\"skyblue\", edgecolor=\"black\")\n",
    "    plt.title(\"Token Length Distribution\")\n",
    "    plt.xlabel(\"Token Length\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32130605-c39d-4694-ade3-2e5d849926a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize token lengths\n",
    "visualize_token_lengths(dataset, text_column=\"Instruction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9134303a-31be-450f-9719-14b440dcd197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentiles of token lengths:\n",
      "50th: 72.0\n",
      "75th: 102.0\n",
      "90th: 163.0\n",
      "95th: 329.0\n",
      "99th: 531.0\n",
      "Suggested max_length (90th percentile): 163.0\n"
     ]
    }
   ],
   "source": [
    "def determine_optimal_max_length(dataset, text_column=\"text\"):\n",
    "    # Initialize tokenizer\n",
    "    \n",
    "    # Tokenize dataset and store token lengths\n",
    "    token_lengths = [len(tokenizer(entry[text_column], truncation=False)[\"input_ids\"]) for entry in dataset]\n",
    "    \n",
    "    # Plot token length distribution\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(token_lengths, bins=10, color=\"skyblue\", edgecolor=\"black\")\n",
    "    plt.title(\"Token Length Distribution\")\n",
    "    plt.xlabel(\"Token Length\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Calculate percentiles for token lengths\n",
    "    percentiles = np.percentile(token_lengths, [50, 75, 90, 95, 99])\n",
    "    print(f\"Percentiles of token lengths:\\n50th: {percentiles[0]}\\n75th: {percentiles[1]}\\n90th: {percentiles[2]}\\n95th: {percentiles[3]}\\n99th: {percentiles[4]}\")\n",
    "    \n",
    "    # Suggest a max_length, e.g., 90th percentile to cover most cases\n",
    "    suggested_max_length = percentiles[2]\n",
    "    print(f\"Suggested max_length (90th percentile): {suggested_max_length}\")\n",
    "    \n",
    "    return suggested_max_length\n",
    "\n",
    "# Determine optimal max_length based on token length distribution\n",
    "suggested_max_length = determine_optimal_max_length(dataset,text_column=\"Response\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "646a9956-b29b-4b4a-8e21-30d048498c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to apply the chat template\n",
    "def apply_chat_template(example):\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": example['Instruction']},\n",
    "        {\"role\": \"assistant\", \"content\": example['Response']}\n",
    "    ]\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        messages, tokenize=False, add_generation_prompt=True\n",
    "    )\n",
    "    return {\"prompt\": prompt}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b3cffd9-ede3-4ea0-906d-e66f0b27b96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the chat templatefunction to the dataset\n",
    "new_dataset = dataset.map(apply_chat_template)\n",
    "new_dataset = new_dataset.train_test_split(0.05) # Let's keep 5% of the data for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "866f4493-960b-465b-990c-16d1fd131b87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 04 Nov 2024\\n\\n<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nWhat is the role of Parliament under clause (2) in relation to the President's authority?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nUnder clause (2), the role of Parliament is to make provision for rules regulating the recruitment and conditions of service of persons appointed to the secretarial staff of the House of the People or the Council of States. Until Parliament takes this action, the President may make such rules after consultation with the Speaker of the House of the People or the Chairman of the Council of States, as applicable. Any rules made by the President shall have effect subject to the provisions of any law made under the said clause.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataset['train'][0]['prompt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f29cb15-bd60-40e3-bcc7-fa265a8bc858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the data\n",
    "def tokenize_function(example):\n",
    "    # Tokenize the 'prompt' text in each example, ensuring consistent sequence length\n",
    "    # padding=\"max_length\" pads all sequences to the max length specified (128 tokens)\n",
    "    # truncation=True cuts off any tokens that exceed this max length\n",
    "    tokens = tokenizer(example['prompt'], padding=\"max_length\", truncation=True, max_length=128)\n",
    "    \n",
    "    # Create 'labels' key to store token labels for training\n",
    "    # Set padding token labels to -100 to ignore them during the loss calculation\n",
    "    # The -100 label is a special value in PyTorch, meaning \"ignore this position in loss computation\"\n",
    "    tokens['labels'] = [\n",
    "        -100 if token == tokenizer.pad_token_id else token for token in tokens['input_ids']\n",
    "    ]\n",
    "    \n",
    "    # Return the tokenized dictionary, now with 'input_ids' and 'labels' keys\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69a725e6-53f3-468c-907c-bb132fad8544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ef6b7bc234b4f14b4deb90087d415c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/24320 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0992a5dd1a454d46a8da68b5354f6dc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1280 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Apply tokenize_function to each row\n",
    "tokenized_dataset = new_dataset.map(tokenize_function)\n",
    "tokenized_dataset = tokenized_dataset.remove_columns(['Instruction', 'Response', 'prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac67cacb-b366-41e0-98f5-a162119f7969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 24320\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 1280\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "565bf102-75ab-4527-b01b-b443cb137f34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[128000, 128000, 128006, 9125, 128007, 271, 38766, 1303, 33025, 2696]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset['train'][0]['input_ids'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb3c8a96-af81-468f-b876-882d972ec332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset['train'][0]['attention_mask'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "405ec9b3-54d1-4ef9-9501-bcda5a809650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[128000, 128000, 128006, 9125, 128007, 271, 38766, 1303, 33025, 2696]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset['train'][0]['labels'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0754b4c-5c4e-4e88-84be-2501d953f7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    r=64,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "model.add_adapter(peft_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f1fda279-2578-44ef-9853-43bef6c76809",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",  # Evaluate at the end of each epoch to reduce interruptions\n",
    "    logging_steps=500,  # Log less frequently to improve speed\n",
    "    save_steps=500,  # Save less frequently to avoid disk usage issues\n",
    "    per_device_train_batch_size=8,  # Higher batch size, assuming GPU or hardware capacity allows\n",
    "    per_device_eval_batch_size=8,  # Matches training batch size\n",
    "    num_train_epochs=3,  # A bit more coverage with larger dataset\n",
    "    fp16=False,  # Keep False if using MacBook or no GPU support\n",
    "    report_to=\"none\",\n",
    "    log_level=\"info\",\n",
    "    learning_rate=2e-5,  # Slightly higher learning rate for faster convergence\n",
    "    max_grad_norm=1.0,  # More conservative gradient clipping for stability\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f60af67f-35e0-44d1-9e27-8fbeee40dba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3584/2935008737.py:2: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "64c1a50a-1eb4-432d-b014-f98c60b5a496",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 24,320\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 9,120\n",
      "  Number of trainable parameters = 6,815,744\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9120' max='9120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9120/9120 39:29, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.406600</td>\n",
       "      <td>1.396925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.368100</td>\n",
       "      <td>1.368543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.359800</td>\n",
       "      <td>1.360918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./results/checkpoint-500\n",
      "Configuration saved in ./results/checkpoint-500/generation_config.json\n",
      "Detected adapters on the model, saving the model in the PEFT format, only adapter weights will be saved.\n",
      "/home/home/dev/venv/lib/python3.11/site-packages/transformers/integrations/peft.py:418: FutureWarning: The `active_adapter` method is deprecated and will be removed in a future version.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/home/.cache/huggingface/hub/models--meta-llama--Llama-3.2-1B-Instruct/snapshots/9213176726f574b556790deb65791e0c5aa438b6/config.json\n",
      "Model config LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": [\n",
      "    128001,\n",
      "    128008,\n",
      "    128009\n",
      "  ],\n",
      "  \"head_dim\": 64,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 2048,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"max_position_embeddings\": 131072,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 16,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": {\n",
      "    \"factor\": 32.0,\n",
      "    \"high_freq_factor\": 4.0,\n",
      "    \"low_freq_factor\": 1.0,\n",
      "    \"original_max_position_embeddings\": 8192,\n",
      "    \"rope_type\": \"llama3\"\n",
      "  },\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.46.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n",
      "To match the expected format of the PEFT library, all keys of the state dict of adapters will be pre-pended with `base_model.model`.\n",
      "Model weights saved in ./results/checkpoint-500/adapter_model.safetensors\n",
      "tokenizer config file saved in ./results/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-500/special_tokens_map.json\n",
      "/home/home/dev/venv/lib/python3.11/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at ../aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "Saving model checkpoint to ./results/checkpoint-1000\n",
      "Configuration saved in ./results/checkpoint-1000/generation_config.json\n",
      "Detected adapters on the model, saving the model in the PEFT format, only adapter weights will be saved.\n",
      "/home/home/dev/venv/lib/python3.11/site-packages/transformers/integrations/peft.py:418: FutureWarning: The `active_adapter` method is deprecated and will be removed in a future version.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/home/.cache/huggingface/hub/models--meta-llama--Llama-3.2-1B-Instruct/snapshots/9213176726f574b556790deb65791e0c5aa438b6/config.json\n",
      "Model config LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": [\n",
      "    128001,\n",
      "    128008,\n",
      "    128009\n",
      "  ],\n",
      "  \"head_dim\": 64,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 2048,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"max_position_embeddings\": 131072,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 16,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": {\n",
      "    \"factor\": 32.0,\n",
      "    \"high_freq_factor\": 4.0,\n",
      "    \"low_freq_factor\": 1.0,\n",
      "    \"original_max_position_embeddings\": 8192,\n",
      "    \"rope_type\": \"llama3\"\n",
      "  },\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.46.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n",
      "To match the expected format of the PEFT library, all keys of the state dict of adapters will be pre-pended with `base_model.model`.\n",
      "Model weights saved in ./results/checkpoint-1000/adapter_model.safetensors\n",
      "tokenizer config file saved in ./results/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-1000/special_tokens_map.json\n",
      "/home/home/dev/venv/lib/python3.11/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at ../aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "Saving model checkpoint to ./results/checkpoint-1500\n",
      "Configuration saved in ./results/checkpoint-1500/generation_config.json\n",
      "Detected adapters on the model, saving the model in the PEFT format, only adapter weights will be saved.\n",
      "/home/home/dev/venv/lib/python3.11/site-packages/transformers/integrations/peft.py:418: FutureWarning: The `active_adapter` method is deprecated and will be removed in a future version.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/home/.cache/huggingface/hub/models--meta-llama--Llama-3.2-1B-Instruct/snapshots/9213176726f574b556790deb65791e0c5aa438b6/config.json\n",
      "Model config LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": [\n",
      "    128001,\n",
      "    128008,\n",
      "    128009\n",
      "  ],\n",
      "  \"head_dim\": 64,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 2048,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"max_position_embeddings\": 131072,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 16,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": {\n",
      "    \"factor\": 32.0,\n",
      "    \"high_freq_factor\": 4.0,\n",
      "    \"low_freq_factor\": 1.0,\n",
      "    \"original_max_position_embeddings\": 8192,\n",
      "    \"rope_type\": \"llama3\"\n",
      "  },\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.46.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n",
      "To match the expected format of the PEFT library, all keys of the state dict of adapters will be pre-pended with `base_model.model`.\n",
      "Model weights saved in ./results/checkpoint-1500/adapter_model.safetensors\n",
      "tokenizer config file saved in ./results/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-1500/special_tokens_map.json\n",
      "/home/home/dev/venv/lib/python3.11/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at ../aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "Saving model checkpoint to ./results/checkpoint-2000\n",
      "Configuration saved in ./results/checkpoint-2000/generation_config.json\n",
      "Detected adapters on the model, saving the model in the PEFT format, only adapter weights will be saved.\n",
      "/home/home/dev/venv/lib/python3.11/site-packages/transformers/integrations/peft.py:418: FutureWarning: The `active_adapter` method is deprecated and will be removed in a future version.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/home/.cache/huggingface/hub/models--meta-llama--Llama-3.2-1B-Instruct/snapshots/9213176726f574b556790deb65791e0c5aa438b6/config.json\n",
      "Model config LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": [\n",
      "    128001,\n",
      "    128008,\n",
      "    128009\n",
      "  ],\n",
      "  \"head_dim\": 64,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 2048,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"max_position_embeddings\": 131072,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 16,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": {\n",
      "    \"factor\": 32.0,\n",
      "    \"high_freq_factor\": 4.0,\n",
      "    \"low_freq_factor\": 1.0,\n",
      "    \"original_max_position_embeddings\": 8192,\n",
      "    \"rope_type\": \"llama3\"\n",
      "  },\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.46.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n",
      "To match the expected format of the PEFT library, all keys of the state dict of adapters will be pre-pended with `base_model.model`.\n",
      "Model weights saved in ./results/checkpoint-2000/adapter_model.safetensors\n",
      "tokenizer config file saved in ./results/checkpoint-2000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-2000/special_tokens_map.json\n",
      "/home/home/dev/venv/lib/python3.11/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at ../aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "Saving model checkpoint to ./results/checkpoint-2500\n",
      "Configuration saved in ./results/checkpoint-2500/generation_config.json\n",
      "Detected adapters on the model, saving the model in the PEFT format, only adapter weights will be saved.\n",
      "/home/home/dev/venv/lib/python3.11/site-packages/transformers/integrations/peft.py:418: FutureWarning: The `active_adapter` method is deprecated and will be removed in a future version.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/home/.cache/huggingface/hub/models--meta-llama--Llama-3.2-1B-Instruct/snapshots/9213176726f574b556790deb65791e0c5aa438b6/config.json\n",
      "Model config LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": [\n",
      "    128001,\n",
      "    128008,\n",
      "    128009\n",
      "  ],\n",
      "  \"head_dim\": 64,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 2048,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"max_position_embeddings\": 131072,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 16,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": {\n",
      "    \"factor\": 32.0,\n",
      "    \"high_freq_factor\": 4.0,\n",
      "    \"low_freq_factor\": 1.0,\n",
      "    \"original_max_position_embeddings\": 8192,\n",
      "    \"rope_type\": \"llama3\"\n",
      "  },\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.46.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n",
      "To match the expected format of the PEFT library, all keys of the state dict of adapters will be pre-pended with `base_model.model`.\n",
      "Model weights saved in ./results/checkpoint-2500/adapter_model.safetensors\n",
      "tokenizer config file saved in ./results/checkpoint-2500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-2500/special_tokens_map.json\n",
      "/home/home/dev/venv/lib/python3.11/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at ../aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "Saving model checkpoint to ./results/checkpoint-3000\n",
      "Configuration saved in ./results/checkpoint-3000/generation_config.json\n",
      "Detected adapters on the model, saving the model in the PEFT format, only adapter weights will be saved.\n",
      "/home/home/dev/venv/lib/python3.11/site-packages/transformers/integrations/peft.py:418: FutureWarning: The `active_adapter` method is deprecated and will be removed in a future version.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/home/.cache/huggingface/hub/models--meta-llama--Llama-3.2-1B-Instruct/snapshots/9213176726f574b556790deb65791e0c5aa438b6/config.json\n",
      "Model config LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": [\n",
      "    128001,\n",
      "    128008,\n",
      "    128009\n",
      "  ],\n",
      "  \"head_dim\": 64,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 2048,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"max_position_embeddings\": 131072,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 16,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": {\n",
      "    \"factor\": 32.0,\n",
      "    \"high_freq_factor\": 4.0,\n",
      "    \"low_freq_factor\": 1.0,\n",
      "    \"original_max_position_embeddings\": 8192,\n",
      "    \"rope_type\": \"llama3\"\n",
      "  },\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.46.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n",
      "To match the expected format of the PEFT library, all keys of the state dict of adapters will be pre-pended with `base_model.model`.\n",
      "Model weights saved in ./results/checkpoint-3000/adapter_model.safetensors\n",
      "tokenizer config file saved in ./results/checkpoint-3000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-3000/special_tokens_map.json\n",
      "/home/home/dev/venv/lib/python3.11/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at ../aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1280\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/checkpoint-3500\n",
      "Configuration saved in ./results/checkpoint-3500/generation_config.json\n",
      "Detected adapters on the model, saving the model in the PEFT format, only adapter weights will be saved.\n",
      "/home/home/dev/venv/lib/python3.11/site-packages/transformers/integrations/peft.py:418: FutureWarning: The `active_adapter` method is deprecated and will be removed in a future version.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/home/.cache/huggingface/hub/models--meta-llama--Llama-3.2-1B-Instruct/snapshots/9213176726f574b556790deb65791e0c5aa438b6/config.json\n",
      "Model config LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": [\n",
      "    128001,\n",
      "    128008,\n",
      "    128009\n",
      "  ],\n",
      "  \"head_dim\": 64,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 2048,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"max_position_embeddings\": 131072,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 16,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": {\n",
      "    \"factor\": 32.0,\n",
      "    \"high_freq_factor\": 4.0,\n",
      "    \"low_freq_factor\": 1.0,\n",
      "    \"original_max_position_embeddings\": 8192,\n",
      "    \"rope_type\": \"llama3\"\n",
      "  },\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.46.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n",
      "To match the expected format of the PEFT library, all keys of the state dict of adapters will be pre-pended with `base_model.model`.\n",
      "Model weights saved in ./results/checkpoint-3500/adapter_model.safetensors\n",
      "tokenizer config file saved in ./results/checkpoint-3500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-3500/special_tokens_map.json\n",
      "/home/home/dev/venv/lib/python3.11/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at ../aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "Saving model checkpoint to ./results/checkpoint-4000\n",
      "Configuration saved in ./results/checkpoint-4000/generation_config.json\n",
      "Detected adapters on the model, saving the model in the PEFT format, only adapter weights will be saved.\n",
      "/home/home/dev/venv/lib/python3.11/site-packages/transformers/integrations/peft.py:418: FutureWarning: The `active_adapter` method is deprecated and will be removed in a future version.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/home/.cache/huggingface/hub/models--meta-llama--Llama-3.2-1B-Instruct/snapshots/9213176726f574b556790deb65791e0c5aa438b6/config.json\n",
      "Model config LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": [\n",
      "    128001,\n",
      "    128008,\n",
      "    128009\n",
      "  ],\n",
      "  \"head_dim\": 64,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 2048,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"max_position_embeddings\": 131072,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 16,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": {\n",
      "    \"factor\": 32.0,\n",
      "    \"high_freq_factor\": 4.0,\n",
      "    \"low_freq_factor\": 1.0,\n",
      "    \"original_max_position_embeddings\": 8192,\n",
      "    \"rope_type\": \"llama3\"\n",
      "  },\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.46.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n",
      "To match the expected format of the PEFT library, all keys of the state dict of adapters will be pre-pended with `base_model.model`.\n",
      "Model weights saved in ./results/checkpoint-4000/adapter_model.safetensors\n",
      "tokenizer config file saved in ./results/checkpoint-4000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-4000/special_tokens_map.json\n",
      "/home/home/dev/venv/lib/python3.11/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at ../aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "Saving model checkpoint to ./results/checkpoint-4500\n",
      "Configuration saved in ./results/checkpoint-4500/generation_config.json\n",
      "Detected adapters on the model, saving the model in the PEFT format, only adapter weights will be saved.\n",
      "/home/home/dev/venv/lib/python3.11/site-packages/transformers/integrations/peft.py:418: FutureWarning: The `active_adapter` method is deprecated and will be removed in a future version.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/home/.cache/huggingface/hub/models--meta-llama--Llama-3.2-1B-Instruct/snapshots/9213176726f574b556790deb65791e0c5aa438b6/config.json\n",
      "Model config LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": [\n",
      "    128001,\n",
      "    128008,\n",
      "    128009\n",
      "  ],\n",
      "  \"head_dim\": 64,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 2048,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"max_position_embeddings\": 131072,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 16,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": {\n",
      "    \"factor\": 32.0,\n",
      "    \"high_freq_factor\": 4.0,\n",
      "    \"low_freq_factor\": 1.0,\n",
      "    \"original_max_position_embeddings\": 8192,\n",
      "    \"rope_type\": \"llama3\"\n",
      "  },\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.46.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n",
      "To match the expected format of the PEFT library, all keys of the state dict of adapters will be pre-pended with `base_model.model`.\n",
      "Model weights saved in ./results/checkpoint-4500/adapter_model.safetensors\n",
      "tokenizer config file saved in ./results/checkpoint-4500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-4500/special_tokens_map.json\n",
      "/home/home/dev/venv/lib/python3.11/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at ../aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "Saving model checkpoint to ./results/checkpoint-5000\n",
      "Configuration saved in ./results/checkpoint-5000/generation_config.json\n",
      "Detected adapters on the model, saving the model in the PEFT format, only adapter weights will be saved.\n",
      "/home/home/dev/venv/lib/python3.11/site-packages/transformers/integrations/peft.py:418: FutureWarning: The `active_adapter` method is deprecated and will be removed in a future version.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/home/.cache/huggingface/hub/models--meta-llama--Llama-3.2-1B-Instruct/snapshots/9213176726f574b556790deb65791e0c5aa438b6/config.json\n",
      "Model config LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": [\n",
      "    128001,\n",
      "    128008,\n",
      "    128009\n",
      "  ],\n",
      "  \"head_dim\": 64,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 2048,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"max_position_embeddings\": 131072,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 16,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": {\n",
      "    \"factor\": 32.0,\n",
      "    \"high_freq_factor\": 4.0,\n",
      "    \"low_freq_factor\": 1.0,\n",
      "    \"original_max_position_embeddings\": 8192,\n",
      "    \"rope_type\": \"llama3\"\n",
      "  },\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.46.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n",
      "To match the expected format of the PEFT library, all keys of the state dict of adapters will be pre-pended with `base_model.model`.\n",
      "Model weights saved in ./results/checkpoint-5000/adapter_model.safetensors\n",
      "tokenizer config file saved in ./results/checkpoint-5000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-5000/special_tokens_map.json\n",
      "/home/home/dev/venv/lib/python3.11/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at ../aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "Saving model checkpoint to ./results/checkpoint-5500\n",
      "Configuration saved in ./results/checkpoint-5500/generation_config.json\n",
      "Detected adapters on the model, saving the model in the PEFT format, only adapter weights will be saved.\n",
      "/home/home/dev/venv/lib/python3.11/site-packages/transformers/integrations/peft.py:418: FutureWarning: The `active_adapter` method is deprecated and will be removed in a future version.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/home/.cache/huggingface/hub/models--meta-llama--Llama-3.2-1B-Instruct/snapshots/9213176726f574b556790deb65791e0c5aa438b6/config.json\n",
      "Model config LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": [\n",
      "    128001,\n",
      "    128008,\n",
      "    128009\n",
      "  ],\n",
      "  \"head_dim\": 64,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 2048,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"max_position_embeddings\": 131072,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 16,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": {\n",
      "    \"factor\": 32.0,\n",
      "    \"high_freq_factor\": 4.0,\n",
      "    \"low_freq_factor\": 1.0,\n",
      "    \"original_max_position_embeddings\": 8192,\n",
      "    \"rope_type\": \"llama3\"\n",
      "  },\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.46.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n",
      "To match the expected format of the PEFT library, all keys of the state dict of adapters will be pre-pended with `base_model.model`.\n",
      "Model weights saved in ./results/checkpoint-5500/adapter_model.safetensors\n",
      "tokenizer config file saved in ./results/checkpoint-5500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-5500/special_tokens_map.json\n",
      "/home/home/dev/venv/lib/python3.11/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at ../aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "Saving model checkpoint to ./results/checkpoint-6000\n",
      "Configuration saved in ./results/checkpoint-6000/generation_config.json\n",
      "Detected adapters on the model, saving the model in the PEFT format, only adapter weights will be saved.\n",
      "/home/home/dev/venv/lib/python3.11/site-packages/transformers/integrations/peft.py:418: FutureWarning: The `active_adapter` method is deprecated and will be removed in a future version.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/home/.cache/huggingface/hub/models--meta-llama--Llama-3.2-1B-Instruct/snapshots/9213176726f574b556790deb65791e0c5aa438b6/config.json\n",
      "Model config LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": [\n",
      "    128001,\n",
      "    128008,\n",
      "    128009\n",
      "  ],\n",
      "  \"head_dim\": 64,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 2048,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"max_position_embeddings\": 131072,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 16,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": {\n",
      "    \"factor\": 32.0,\n",
      "    \"high_freq_factor\": 4.0,\n",
      "    \"low_freq_factor\": 1.0,\n",
      "    \"original_max_position_embeddings\": 8192,\n",
      "    \"rope_type\": \"llama3\"\n",
      "  },\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.46.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n",
      "To match the expected format of the PEFT library, all keys of the state dict of adapters will be pre-pended with `base_model.model`.\n",
      "Model weights saved in ./results/checkpoint-6000/adapter_model.safetensors\n",
      "tokenizer config file saved in ./results/checkpoint-6000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-6000/special_tokens_map.json\n",
      "/home/home/dev/venv/lib/python3.11/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at ../aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1280\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/checkpoint-6500\n",
      "Configuration saved in ./results/checkpoint-6500/generation_config.json\n",
      "Detected adapters on the model, saving the model in the PEFT format, only adapter weights will be saved.\n",
      "/home/home/dev/venv/lib/python3.11/site-packages/transformers/integrations/peft.py:418: FutureWarning: The `active_adapter` method is deprecated and will be removed in a future version.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/home/.cache/huggingface/hub/models--meta-llama--Llama-3.2-1B-Instruct/snapshots/9213176726f574b556790deb65791e0c5aa438b6/config.json\n",
      "Model config LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": [\n",
      "    128001,\n",
      "    128008,\n",
      "    128009\n",
      "  ],\n",
      "  \"head_dim\": 64,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 2048,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"max_position_embeddings\": 131072,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 16,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": {\n",
      "    \"factor\": 32.0,\n",
      "    \"high_freq_factor\": 4.0,\n",
      "    \"low_freq_factor\": 1.0,\n",
      "    \"original_max_position_embeddings\": 8192,\n",
      "    \"rope_type\": \"llama3\"\n",
      "  },\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.46.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n",
      "To match the expected format of the PEFT library, all keys of the state dict of adapters will be pre-pended with `base_model.model`.\n",
      "Model weights saved in ./results/checkpoint-6500/adapter_model.safetensors\n",
      "tokenizer config file saved in ./results/checkpoint-6500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-6500/special_tokens_map.json\n",
      "/home/home/dev/venv/lib/python3.11/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at ../aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "Saving model checkpoint to ./results/checkpoint-7000\n",
      "Configuration saved in ./results/checkpoint-7000/generation_config.json\n",
      "Detected adapters on the model, saving the model in the PEFT format, only adapter weights will be saved.\n",
      "/home/home/dev/venv/lib/python3.11/site-packages/transformers/integrations/peft.py:418: FutureWarning: The `active_adapter` method is deprecated and will be removed in a future version.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/home/.cache/huggingface/hub/models--meta-llama--Llama-3.2-1B-Instruct/snapshots/9213176726f574b556790deb65791e0c5aa438b6/config.json\n",
      "Model config LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": [\n",
      "    128001,\n",
      "    128008,\n",
      "    128009\n",
      "  ],\n",
      "  \"head_dim\": 64,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 2048,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"max_position_embeddings\": 131072,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 16,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": {\n",
      "    \"factor\": 32.0,\n",
      "    \"high_freq_factor\": 4.0,\n",
      "    \"low_freq_factor\": 1.0,\n",
      "    \"original_max_position_embeddings\": 8192,\n",
      "    \"rope_type\": \"llama3\"\n",
      "  },\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.46.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n",
      "To match the expected format of the PEFT library, all keys of the state dict of adapters will be pre-pended with `base_model.model`.\n",
      "Model weights saved in ./results/checkpoint-7000/adapter_model.safetensors\n",
      "tokenizer config file saved in ./results/checkpoint-7000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-7000/special_tokens_map.json\n",
      "/home/home/dev/venv/lib/python3.11/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at ../aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "Saving model checkpoint to ./results/checkpoint-7500\n",
      "Configuration saved in ./results/checkpoint-7500/generation_config.json\n",
      "Detected adapters on the model, saving the model in the PEFT format, only adapter weights will be saved.\n",
      "/home/home/dev/venv/lib/python3.11/site-packages/transformers/integrations/peft.py:418: FutureWarning: The `active_adapter` method is deprecated and will be removed in a future version.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/home/.cache/huggingface/hub/models--meta-llama--Llama-3.2-1B-Instruct/snapshots/9213176726f574b556790deb65791e0c5aa438b6/config.json\n",
      "Model config LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": [\n",
      "    128001,\n",
      "    128008,\n",
      "    128009\n",
      "  ],\n",
      "  \"head_dim\": 64,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 2048,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"max_position_embeddings\": 131072,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 16,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": {\n",
      "    \"factor\": 32.0,\n",
      "    \"high_freq_factor\": 4.0,\n",
      "    \"low_freq_factor\": 1.0,\n",
      "    \"original_max_position_embeddings\": 8192,\n",
      "    \"rope_type\": \"llama3\"\n",
      "  },\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.46.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n",
      "To match the expected format of the PEFT library, all keys of the state dict of adapters will be pre-pended with `base_model.model`.\n",
      "Model weights saved in ./results/checkpoint-7500/adapter_model.safetensors\n",
      "tokenizer config file saved in ./results/checkpoint-7500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-7500/special_tokens_map.json\n",
      "/home/home/dev/venv/lib/python3.11/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at ../aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "Saving model checkpoint to ./results/checkpoint-8000\n",
      "Configuration saved in ./results/checkpoint-8000/generation_config.json\n",
      "Detected adapters on the model, saving the model in the PEFT format, only adapter weights will be saved.\n",
      "/home/home/dev/venv/lib/python3.11/site-packages/transformers/integrations/peft.py:418: FutureWarning: The `active_adapter` method is deprecated and will be removed in a future version.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/home/.cache/huggingface/hub/models--meta-llama--Llama-3.2-1B-Instruct/snapshots/9213176726f574b556790deb65791e0c5aa438b6/config.json\n",
      "Model config LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": [\n",
      "    128001,\n",
      "    128008,\n",
      "    128009\n",
      "  ],\n",
      "  \"head_dim\": 64,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 2048,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"max_position_embeddings\": 131072,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 16,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": {\n",
      "    \"factor\": 32.0,\n",
      "    \"high_freq_factor\": 4.0,\n",
      "    \"low_freq_factor\": 1.0,\n",
      "    \"original_max_position_embeddings\": 8192,\n",
      "    \"rope_type\": \"llama3\"\n",
      "  },\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.46.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n",
      "To match the expected format of the PEFT library, all keys of the state dict of adapters will be pre-pended with `base_model.model`.\n",
      "Model weights saved in ./results/checkpoint-8000/adapter_model.safetensors\n",
      "tokenizer config file saved in ./results/checkpoint-8000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-8000/special_tokens_map.json\n",
      "/home/home/dev/venv/lib/python3.11/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at ../aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "Saving model checkpoint to ./results/checkpoint-8500\n",
      "Configuration saved in ./results/checkpoint-8500/generation_config.json\n",
      "Detected adapters on the model, saving the model in the PEFT format, only adapter weights will be saved.\n",
      "/home/home/dev/venv/lib/python3.11/site-packages/transformers/integrations/peft.py:418: FutureWarning: The `active_adapter` method is deprecated and will be removed in a future version.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/home/.cache/huggingface/hub/models--meta-llama--Llama-3.2-1B-Instruct/snapshots/9213176726f574b556790deb65791e0c5aa438b6/config.json\n",
      "Model config LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": [\n",
      "    128001,\n",
      "    128008,\n",
      "    128009\n",
      "  ],\n",
      "  \"head_dim\": 64,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 2048,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"max_position_embeddings\": 131072,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 16,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": {\n",
      "    \"factor\": 32.0,\n",
      "    \"high_freq_factor\": 4.0,\n",
      "    \"low_freq_factor\": 1.0,\n",
      "    \"original_max_position_embeddings\": 8192,\n",
      "    \"rope_type\": \"llama3\"\n",
      "  },\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.46.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n",
      "To match the expected format of the PEFT library, all keys of the state dict of adapters will be pre-pended with `base_model.model`.\n",
      "Model weights saved in ./results/checkpoint-8500/adapter_model.safetensors\n",
      "tokenizer config file saved in ./results/checkpoint-8500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-8500/special_tokens_map.json\n",
      "/home/home/dev/venv/lib/python3.11/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at ../aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "Saving model checkpoint to ./results/checkpoint-9000\n",
      "Configuration saved in ./results/checkpoint-9000/generation_config.json\n",
      "Detected adapters on the model, saving the model in the PEFT format, only adapter weights will be saved.\n",
      "/home/home/dev/venv/lib/python3.11/site-packages/transformers/integrations/peft.py:418: FutureWarning: The `active_adapter` method is deprecated and will be removed in a future version.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/home/.cache/huggingface/hub/models--meta-llama--Llama-3.2-1B-Instruct/snapshots/9213176726f574b556790deb65791e0c5aa438b6/config.json\n",
      "Model config LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": [\n",
      "    128001,\n",
      "    128008,\n",
      "    128009\n",
      "  ],\n",
      "  \"head_dim\": 64,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 2048,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"max_position_embeddings\": 131072,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 16,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": {\n",
      "    \"factor\": 32.0,\n",
      "    \"high_freq_factor\": 4.0,\n",
      "    \"low_freq_factor\": 1.0,\n",
      "    \"original_max_position_embeddings\": 8192,\n",
      "    \"rope_type\": \"llama3\"\n",
      "  },\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.46.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n",
      "To match the expected format of the PEFT library, all keys of the state dict of adapters will be pre-pended with `base_model.model`.\n",
      "Model weights saved in ./results/checkpoint-9000/adapter_model.safetensors\n",
      "tokenizer config file saved in ./results/checkpoint-9000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-9000/special_tokens_map.json\n",
      "/home/home/dev/venv/lib/python3.11/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at ../aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "Saving model checkpoint to ./results/checkpoint-9120\n",
      "Configuration saved in ./results/checkpoint-9120/generation_config.json\n",
      "Detected adapters on the model, saving the model in the PEFT format, only adapter weights will be saved.\n",
      "/home/home/dev/venv/lib/python3.11/site-packages/transformers/integrations/peft.py:418: FutureWarning: The `active_adapter` method is deprecated and will be removed in a future version.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/home/.cache/huggingface/hub/models--meta-llama--Llama-3.2-1B-Instruct/snapshots/9213176726f574b556790deb65791e0c5aa438b6/config.json\n",
      "Model config LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": [\n",
      "    128001,\n",
      "    128008,\n",
      "    128009\n",
      "  ],\n",
      "  \"head_dim\": 64,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 2048,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"max_position_embeddings\": 131072,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 16,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": {\n",
      "    \"factor\": 32.0,\n",
      "    \"high_freq_factor\": 4.0,\n",
      "    \"low_freq_factor\": 1.0,\n",
      "    \"original_max_position_embeddings\": 8192,\n",
      "    \"rope_type\": \"llama3\"\n",
      "  },\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.46.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n",
      "To match the expected format of the PEFT library, all keys of the state dict of adapters will be pre-pended with `base_model.model`.\n",
      "Model weights saved in ./results/checkpoint-9120/adapter_model.safetensors\n",
      "tokenizer config file saved in ./results/checkpoint-9120/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-9120/special_tokens_map.json\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1280\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=9120, training_loss=1.406967484323602, metrics={'train_runtime': 2369.3193, 'train_samples_per_second': 30.794, 'train_steps_per_second': 3.849, 'total_flos': 5.519947957744435e+16, 'train_loss': 1.406967484323602, 'epoch': 3.0})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ac955c33-ea37-48ee-8c8a-b295cf705b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./fine-tuned-model\n",
      "Configuration saved in ./fine-tuned-model/generation_config.json\n",
      "Detected adapters on the model, saving the model in the PEFT format, only adapter weights will be saved.\n",
      "/home/home/dev/venv/lib/python3.11/site-packages/transformers/integrations/peft.py:418: FutureWarning: The `active_adapter` method is deprecated and will be removed in a future version.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/home/.cache/huggingface/hub/models--meta-llama--Llama-3.2-1B-Instruct/snapshots/9213176726f574b556790deb65791e0c5aa438b6/config.json\n",
      "Model config LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": [\n",
      "    128001,\n",
      "    128008,\n",
      "    128009\n",
      "  ],\n",
      "  \"head_dim\": 64,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 2048,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"max_position_embeddings\": 131072,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 16,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": {\n",
      "    \"factor\": 32.0,\n",
      "    \"high_freq_factor\": 4.0,\n",
      "    \"low_freq_factor\": 1.0,\n",
      "    \"original_max_position_embeddings\": 8192,\n",
      "    \"rope_type\": \"llama3\"\n",
      "  },\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.46.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n",
      "To match the expected format of the PEFT library, all keys of the state dict of adapters will be pre-pended with `base_model.model`.\n",
      "Model weights saved in ./fine-tuned-model/adapter_model.safetensors\n",
      "tokenizer config file saved in ./fine-tuned-model/tokenizer_config.json\n",
      "Special tokens file saved in ./fine-tuned-model/special_tokens_map.json\n",
      "tokenizer config file saved in ./fine-tuned-model/tokenizer_config.json\n",
      "Special tokens file saved in ./fine-tuned-model/special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./fine-tuned-model/tokenizer_config.json',\n",
       " './fine-tuned-model/special_tokens_map.json',\n",
       " './fine-tuned-model/tokenizer.json')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model and tokenizer\n",
    "trainer.save_model(\"./fine-tuned-model\")\n",
    "tokenizer.save_pretrained(\"./fine-tuned-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968fcd2d-eb2d-4c22-b21b-5000aa69d6a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
